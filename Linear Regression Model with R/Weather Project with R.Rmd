---
title: "Weather Analysis and Prediction"
author: "Antoni Joan Bosch Rubio"
date: "2023-11-29"
output:
  github_document: default
  html_notebook: default
editor_options:
  chunk_output_type: inline
---
## EXERCICES 

## Installing packages and loading libraries
```{r warning=FALSE,message=FALSE}
# List of packages
packages <- c("doBy", "ggplot2", "dplyr", "car", "MASS", "lmtest", "caret", "psych", "corrplot", "RcmdrMisc")

# Function to check and install packages
check_and_install <- function(pkg){
  if (!require(pkg, character.only = TRUE)){
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

# Apply the function to each package
sapply(packages, check_and_install)
```
## Loading dataset
```{r warning=FALSE,message=FALSE}
dataset <- readr::read_csv("day.csv")
head(dataset)
```

## Cleaning data
```{r warning=FALSE,message=FALSE}
#Converting dataset to a dataframe
raw_data <- as.data.frame(dataset)
#Checking data info
str(raw_data)

#Changing data type of qualitative features
qualitative_features <- c("season", "yr", "mnth", "holiday", "weekday", "workingday", "weathersit")
raw_data[qualitative_features] <- lapply(raw_data[qualitative_features], factor)

#Checking for missing data
sum(is.na(raw_data))

#Checking for duplicated values
sum(duplicated(raw_data))

#Converting "dtday" to Date format
raw_data$dteday <- as.Date(raw_data$dteday, format = "%Y-%m-%d")

#Substracting the 1st column (instant)
clean_data <- raw_data[,-1]

#Re-coding qualitative features
clean_data$season <- factor(clean_data$season, levels = c(1,2,3,4), labels = c("Spring", "Summer", "Winter", "Autumn"))
clean_data$yr <- factor(clean_data$yr, levels = c(0,1), labels = c("2011", "2012"))
clean_data$mnth <- factor(clean_data$mnth, levels = c(1,2,3,4,5,6,7,8,9,10,11,12), labels = c("January", "February", "March", "April","May","June","July","August","September","October","November","December"))
clean_data$holiday <- factor(clean_data$holiday, levels = c(0,1), labels = c("No", "Yes"))
#Weekday actually goes from 0 to 6 in the data(doesn't correspond with the feature's dictionary)
clean_data$weekday <- factor(clean_data$weekday, levels = c(0,1,2,3,4,5,6), labels = c("Monday", "Tuesday", "Wednesday", "Thursday","Friday","Saturday", "Sunday"))
clean_data$workingday<- factor(clean_data$workingday, levels = c(0,1), labels = c("No", "Yes"))
clean_data$weathersit <- factor(clean_data$weathersit, levels = c(1, 2, 3,4), labels = c("Sunny", "Cloudy", "Light R/S","Heavy R/S" ))
head(clean_data)
```

### EXERCICE 1
Analyze descriptively (through tabular and graphical representations) and briefly comment on all the variables included in the database except for the record variable (instant}).

```{r warning=FALSE,message=FALSE}
#Tabular descriptive analysis for numerical features
numeric_features <- c("temp", "atemp", "hum", "windspeed", "cnt")
numeric_descr <- as.data.frame(describe(clean_data[numeric_features]))
print(numeric_descr)

#Graphical descriptive analysis for numerical features

for (feature in numeric_features){
  data <- clean_data[,feature]
  ylim_values <- range(data)
  boxplot(data, xlab = feature, ylim = ylim_values)
}
```

```{r warning=FALSE,message=FALSE}
#Tabular descriptive analysis for qualitative features
qualit_descriptions <- list()

for (feature in qualitative_features) {
  df <- as.data.frame(table(clean_data[feature]))
  df$Relative_freq <- df$Freq / sum(df$Freq)
  
  qualit_descriptions[[feature]] <- df
}
print(qualit_descriptions)

#Graphical descriptive analysis of qualitative features
# Function to create plot per feature 
create_barplot <- function(feature, data) {
  # Get data from the current feature
  df <- data[[feature]]
  
  #Vector of bar colors
  colors <- rainbow(nrow(df))
  
  #Bar plot
  barplot(df$Relative_freq, 
          main = paste("Relative Frequencies", feature), 
          xlab = "Levels", 
          ylab = "Relative Frequency", 
          col = colors,
          names.arg = df[,1],  # Usar la primera columna para los nombres
          ylim = c(0, max(df$Relative_freq) + 0.1),  # Ajustar el rango del eje y para dar espacio a los textos
          las = 2)  # Rotar las etiquetas 45 grados
  
  # Bar labels
  text(x = seq_along(df$Relative_freq), 
       y = df$Relative_freq + 0.01,  # Ajustar la posición vertical del texto
       labels = sprintf("%.2f", df$Relative_freq), 
       pos = 3,  # Posición 3 coloca el texto arriba de la barra
       cex = 0.8, 
       col = "blue",
       srt = 45)
}

# Apply the function for each feature
for (feature in names(qualit_descriptions)) {
  create_barplot(feature, qualit_descriptions)
}
```

```{r warning=FALSE,message=FALSE}

#Tabular descriptive analysis for date feature
#Checking start and end of records
start_end_date <- data.frame(c((min(clean_data$dteday)), max(clean_data$dteday)), row.names = c("Start", "End"))
colnames(start_end_date) <- "Dates"
print(start_end_date)

#Checking if there is only 1 record for each date recorded
duplicated_dates <-clean_data[duplicated(clean_data$dteday), ]
print(paste("Number of duplicated dates: ", nrow(duplicated_dates)))
if(nrow(duplicated_dates) > 0) print(duplicated_dates)

#Checking if there is any gap in the time series
all_dates <- seq(from = start_end_date["Start", "Dates"], to = start_end_date["End", "Dates"], by = "day")
missing_dates <- setdiff(all_dates, clean_data$dteday)
print(paste("Number of missing dates: ", length(missing_dates)))
```

### EXERCICE 2
Perform and briefly comment on bivariate analyses between the response variable (cnt) and the rest of the variables in the database except for the record variable (instant).

```{r warning=FALSE,message=FALSE,fig.width=12,fig.height=12}
dateless_data <- clean_data[,-1]
#Bivariant analysis cnt vs qualitative features
#qualitative_features <- c("season", "yr", "mnth", "holiday", "weekday", "workingday", "weathersit")
qualitative_features <- c("season", "yr", "mnth", "holiday", "weekday", "workingday", "weathersit")
for (feature in qualitative_features){
  feature_cnt <- summaryBy(as.formula(paste("cnt ~", feature)), data = dateless_data, id = NULL, FUN = c(mean, min ,max, sd))
  assign(paste0(feature, "_cnt"), feature_cnt)
  print(feature_cnt)
}
```
```{r warning=FALSE,message=FALSE}
#Bivariant analysis cnt vs numerical features
numeric_features2 <-  numeric_features[-5]
for (feature in numeric_features2){
 scatterplot(as.formula(paste("cnt ~", feature)), data = clean_data)
}
```
```{r warning=FALSE,message=FALSE}
#Correlation heatmap of features
cor_data <- clean_data[,numeric_features]
correlation_matrix <- cor(cor_data)
corrplot(correlation_matrix, method = 'color')
```

### EXERCICE 3

Divide the sample into a training sample (70%) and a test sample (30%), previously using the set.seed(123) instruction. Carry out a multiple regression model to predict the cnt variable including only the numerical variables related to weather conditions. Interpret its coefficients, as well as the overall utility of the model. Use only the training sample.

```{r warning=FALSE,message=FALSE}
set.seed(123)
train_sample <- dateless_data %>% sample_frac(0.7)
test_sample <- dateless_data %>% anti_join(train_sample)
mult_reg_model <- lm(cnt ~ windspeed + hum + atemp + temp, data = train_sample)
summary(mult_reg_model)

avPlots(mult_reg_model)
```

### EXERCICE 4

Add the categorical predictor \texttt{weathersit} to the previous model and interpret its coefficients, also interpreting its overall utility. Use only the training sample.  

```{r warning=FALSE,message=FALSE,fig.width=12,fig.height=12}
model2 <- lm (cnt ~ windspeed + hum + atemp + temp + weathersit, data = train_sample)
summary(model2)
avPlots(model2)
anova(mult_reg_model, model2)
```


### EXERCICE 5

Add the interaction term windspeed*hum to the model from the previous question, interpret the new coefficients and carry out a global contrast associated with the resulting model. Use only the training sample.

```{r warning=FALSE,message=FALSE}
model3 <- lm (cnt ~ windspeed + hum + atemp + temp + weathersit + windspeed*hum, data = train_sample)
summary(model3)
avPlots(model3)
anova(model2, model3)
```

### EXERCICE 6

Use the *backward elimination* method to reduce the level of complexity of the previous model. Use only the training sample.
```{r warning=FALSE,message=FALSE,fig.width=12,fig.height=12}
model4 <- stepwise(model3, direction='backward', criterion='BIC', trace = 0) 
summary(model4)
avPlots(model4)
anova(model3,model4)
```

### EXERCICE 7

Validate the theoretical assumptions of the linear model using statistical contrasts and graphs using the model obtained in the previous question and using only the training sample. Additionally, report some fit indicator for the test sample.

```{r warning=FALSE,message=FALSE}
# Linearity
predicted <- predict(model4)
plot(train_sample$cnt, predicted)
abline(0,1)

# We can see that the linearity assumption is fulfilled.
```

```{r warning=FALSE,message=FALSE}
# Independence
durbinWatsonTest(model4)

# D-W Statistic of 2, there is no autocorrelation. A pvalue of .69 means that we cannot reject the null hypothesis of no autocorrelation. This means that our model meets the assumption of independence of errors.
```

```{r warning=FALSE,message=FALSE}
# Homoscedasticity
plot(predicted, residuals(model4))
abline(h=0, lty = 2)

# The curve is a straight line parallel to the X-axis, showing that there might be variations between the predicted and the residual value. This variation should be constant, following the assumption of homoscedasticity.
```

```{r warning=FALSE,message=FALSE}
# Normality
qqnorm(residuals(model4))
qqline(residuals(model4))
shapiro.test(residuals(model4))

# We can see that our pvalue is less than 0.05, providing enough evidence to reject the null-hypothesis, our residuals are not normally distributed. Also, our Q-Q plot confirms this, since the residuals are not completely falling on a straight line.
```

```{r warning=FALSE,message=FALSE}
# Multicolinearity
vif_values <- vif(model4)
print(vif_values)
# There are no significant issues of multicolinearity
```

```{r warning=FALSE,message=FALSE}
# Fit indicator
predictions_train <- model4 %>% predict(train_sample)
data.frame(R2 = R2(predictions_train, train_sample$cnt),
           RMSE = RMSE(predictions_train, train_sample$cnt),
           MAE = MAE(predictions_train, train_sample$cnt))
predictions <- model4 %>% predict(test_sample)
data.frame(R2 = R2(predictions, test_sample$cnt),
           RMSE = RMSE(predictions, test_sample$cnt),
           MAE = MAE(predictions, test_sample$cnt))
PER1<-RMSE(predictions_train, train_sample$cnt)/mean(train_sample$cnt)
cat("Prediction error rate train:", PER1)
PER2<-RMSE(predictions, test_sample$cnt)/mean(test_sample$cnt)
cat("Prediction error rate test:", PER2)

# Lower error rate in prediction for trained model.
# When chosing between 2 models, the one with lower RMSE for the test_sample(not trained) should be the prefered
```
